Assume $f^0: \mathcal{X} \rightarrow \mathcal{Y}$ is a BB, trained on a dataset \{$\mathcal{X}$, $\mathcal{Y}$, $\mathcal{C}$\}, with $\mathcal{X}$, $\mathcal{Y}$, and $\mathcal{C}$ being the images, classes, and human interpretable concepts, respectively. Further, $f^0=h^0 \circ \Phi$. Given a learnable projection $t: \Phi \rightarrow \mathcal{C}$, the iterative algorithm \emph{Route, Interpret, and Repeat (RIR)}~\cite{ghosh2023route} carves out an interpretable expert ($g^k: \mathcal{C} \rightarrow \mathcal{Y}$) and a residual ($r^k :\Phi\rightarrow\mathcal{Y}$) at each iteration $k$, explaining the interpretable and uninterpretable components of $f^0$ respectively. Each expert specializes in a subset of data, defined by that iteration's coverage $\tau^k$. 
The algorithm learns three functions: (1) a set of probabilistic selectors \emph{routing} a sample to the corresponding expert or the residual, (2) a set of experts, each generating sample-specific FOLs in terms of the concepts to \emph{interpret} the BB, and (3) \emph{repeating} with residuals for the unexplained samples.


