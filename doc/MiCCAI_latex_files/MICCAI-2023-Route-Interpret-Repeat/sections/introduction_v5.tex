Model generalizability is one of the main challenges of AI, especially in high stake applications such as healthcare. While NN models achieve state-of-the-art (SOTA) performance in disease classification~\cite{irvin2019chexpert, rajpurkar2017chexnet, yu2022anatomy}, they are brittle to small shifts in the data distribution~\cite{guan2021domain} caused by a change in acquisition protocol or scanner type~\cite{yan2020mri}. Fine-tuning all or some layers of a NN model on the target domain can alleviate this problem~\cite{chu2016best}, but it requires a substantial amount of labeled data and be computationally expensive~\cite{wang2017growing, kandel2020deeply}. In contrast, radiologists follow fairly generalizable and comprehensible rules. Specifically, they search for patterns of changes in anatomy to read abnormality from an image and apply logical rules for specific diagnoses. This approach is transparent and closer to an interpretable-by-design approach in AI. We develop a method to extract a mixture of interpretable models based on clinical concepts, similar to radiologists' rules, from a pre-trained NN. Such a model is more data- and computation-efficient than the original NN for fine-tuning to a new distribution.

 Standard interpretable by design method~\cite{rudin2022interpretable} finds an interpretable function (\eg linear regression or rule-based) between human-interpretable concepts and final output~\cite{koh2020concept}. A concept classifier~\cite{sarkar2021inducing, zarlenga2022concept} detects the presence or absence of concepts in an image. In medical images, previous research uses TCAV scores~\cite{kim2017interpretability} to quantify the role of a concept on the final prediction~\cite{yeche2019ubs, graziani2020concept, clough2019global}, but the concept-based interpretable models have been mostly unexplored.
% and used for medical imaging purposes~\cite{yeche2019ubs, graziani2020concept, clough2019global}. 
Recently Posthoc Concept Bottleneck models (PCBMs)~\cite{yuksekgonul2022post} identify concepts from the embeddings of BB. However, the common design choice amongst those methods relies on a single interpretable classifier to explain the entire dataset, cannot capture the diverse sample-specific explanations, and performs poorly than their BB variants.

\textbf{Our contributions.}
This paper proposes a novel data-efficient interpretable method that can be transferred to an unseen domain. Our interpretable model is built upon human-interpretable concepts and can provide sample-specific explanations for diverse disease subtypes and pathological patterns. Beginning with a BB in the source domain, we progressively extract a mixture of interpretable models from BB. Our method includes a set of selectors routing the explainable samples through the interpretable models. The interpretable models provide First-order-logic (FOL) explanations for the samples they cover. The remaining unexplained samples are routed through the residuals until they are covered by a successive interpretable model. We repeat the process until we cover a desired fraction of data. Due to class imbalance in large CXR datasets, early interpretable models tend to cover all samples with disease present while ignoring disease subgroups and pathological heterogeneity. We address this problem by estimating the class-stratified coverage from the total data coverage. We then finetune the interpretable models in the target domain. The target domain lacks concept-level annotation since they are expensive. Hence, we learn a concept detector in the target domain with a pseudo labeling approach~\cite{lee2013pseudo} and finetune the interpretable models. Our work is the first to apply concept-based methods to CXRs and transfer them between domains. 

% Our experiments demonstrate that our method (1) is able to capture diverse instance-specific concepts in the FOL explanations compared to all other interpretable models, (2) does not compromise the performance, (3) is able to identify ``harder'' samples, (4) can be efficiently transferred from source to target domain.
 
